{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = 'google/pegasus-xsum'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is the story of how i ended up with a nasty gash on my leg.']\n"
     ]
    }
   ],
   "source": [
    "src_text = [\n",
    "    \"\"\"this happened 5/6 years ago so my whole family every xmas day goes around to my aunties for celebrations. my cousin (of course) was there and he\n",
    "asked if i wanted to play cops and robbers. i accepted of course. now, next to the side of my aunts house is a little area with a small fence, a covered\n",
    "water tank and super duper sharp stones. my cousin (who was the cop) was gaining on me. i (tried) to jump over the fence, aaand i failed the jump\n",
    "and went crashing onto the gravel, my leg hitting the sharpest bit and, then the next thing i knew it had a nasty gash.\"\"\"\n",
    "]\n",
    "\n",
    "\n",
    "#batch = tokenizer.prepare_seq2seq_batch(src_text, truncation=True, padding='longest').to(torch_device)\n",
    "batch = tokenizer.prepare_seq2seq_batch(src_text, truncation=True, padding='longest', return_tensors='pt').to(torch_device)\n",
    "translated = model.generate(**batch)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "print(tgt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I’ve been meaning to write this post for a long time.']\n"
     ]
    }
   ],
   "source": [
    "src_text = [\n",
    "    \"\"\"throwaway here for obvious reasons.. today my friends and i decided to go off-roading in nowhereland. we packed up all our stuff, made the roughly\n",
    "hour drive off to the mountains to make a fire, go fishing and just talk about life until we got too tired to stay any longer. we got everything packed\n",
    "up and brought along one of my friends’ dog because she’s awesome and loves the outdoors. the dog was flipping out in the suv on the way to the\n",
    "path because she knew was a kick-ass day she was about to have breaking out of her normally lame, domesticated dog life. my friends decided to\n",
    "drink during the off-roading adventure, which was fine because i volunteered to drive since i cannot drink alcohol (mouth is wired shut [long story\n",
    "but i can’t drink alcohol for a while]) so we were playing it safe. the dog couldn’t be any happier and was about to jump out of the truck (literally)\n",
    "when we got there so the dog’s owner let her get out and run along side of us while we drove the dirt road up to the destination for the fire. as i was\n",
    "driving, the dog went in and out of vision, mostly biting the tires as most dogs do, playing around. the owner kept asking us (the two guys up front)\n",
    "if we could see her. we said yes, and kept driving. as i was driving at no more than 5-10mph along the dirt road, i could hear the dog biting at the\n",
    "tires playfully, but we just laughed it off bc we thought she was having fun. the horrible, seconds-long event that ensued was me feeling the dreaded\n",
    "’double-thud’ under the tires and heard the dog yelp in pain. i instantly stopped the ... .\"\"\"\n",
    "]\n",
    "\n",
    "\n",
     "#batch = tokenizer.prepare_seq2seq_batch(src_text, truncation=True, padding='longest').to(torch_device)\n",
    "batch = tokenizer.prepare_seq2seq_batch(src_text, truncation=True, padding='longest', return_tensors='pt').to(torch_device)\n",
    "translated = model.generate(**batch)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "print(tgt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'google/pegasus-large'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the dog couldn’t be any happier and was about to jump out of the truck (literally) when we got there so the dog’s owner let her get out and run along side of us while we drove the dirt road up to the destination for the fire. as i was driving at no more than 5-10mph along the dirt road, i could hear the dog biting at the tires playfully, but we just laughed it off bc we thought she was having fun.']\n"
     ]
    }
   ],
   "source": [
    "src_text = [\n",
    "    \"\"\"throwaway here for obvious reasons.. today my friends and i decided to go off-roading in nowhereland. we packed up all our stuff, made the roughly\n",
    "hour drive off to the mountains to make a fire, go fishing and just talk about life until we got too tired to stay any longer. we got everything packed\n",
    "up and brought along one of my friends’ dog because she’s awesome and loves the outdoors. the dog was flipping out in the suv on the way to the\n",
    "path because she knew was a kick-ass day she was about to have breaking out of her normally lame, domesticated dog life. my friends decided to\n",
    "drink during the off-roading adventure, which was fine because i volunteered to drive since i cannot drink alcohol (mouth is wired shut [long story\n",
    "but i can’t drink alcohol for a while]) so we were playing it safe. the dog couldn’t be any happier and was about to jump out of the truck (literally)\n",
    "when we got there so the dog’s owner let her get out and run along side of us while we drove the dirt road up to the destination for the fire. as i was\n",
    "driving, the dog went in and out of vision, mostly biting the tires as most dogs do, playing around. the owner kept asking us (the two guys up front)\n",
    "if we could see her. we said yes, and kept driving. as i was driving at no more than 5-10mph along the dirt road, i could hear the dog biting at the\n",
    "tires playfully, but we just laughed it off bc we thought she was having fun. the horrible, seconds-long event that ensued was me feeling the dreaded\n",
    "’double-thud’ under the tires and heard the dog yelp in pain. i instantly stopped the ... .\"\"\"\n",
    "]\n",
    "\n",
    "\n",
     "#batch = tokenizer.prepare_seq2seq_batch(src_text, truncation=True, padding='longest').to(torch_device)\n",
    "batch = tokenizer.prepare_seq2seq_batch(src_text, truncation=True, padding='longest', return_tensors='pt').to(torch_device)\n",
    "translated = model.generate(**batch)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "print(tgt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['now, next to the side of my aunts house is a little area with a small fence, a covered water tank and super duper sharp stones.']\n"
     ]
    }
   ],
   "source": [
    "src_text = [\n",
    "    \"\"\"this happened 5/6 years ago so my whole family every xmas day goes around to my aunties for celebrations. my cousin (of course) was there and he\n",
    "asked if i wanted to play cops and robbers. i accepted of course. now, next to the side of my aunts house is a little area with a small fence, a covered\n",
    "water tank and super duper sharp stones. my cousin (who was the cop) was gaining on me. i (tried) to jump over the fence, aaand i failed the jump\n",
    "and went crashing onto the gravel, my leg hitting the sharpest bit and, then the next thing i knew it had a nasty gash.\"\"\"\n",
    "]\n",
    "\n",
    "\n",
    "#batch = tokenizer.prepare_seq2seq_batch(src_text, truncation=True, padding='longest').to(torch_device)\n",
    "batch = tokenizer.prepare_seq2seq_batch(src_text, truncation=True, padding='longest', return_tensors='pt').to(torch_device)\n",
    "translated = model.generate(**batch)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "print(tgt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'google/pegasus-reddit_tifu'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"played cops and robbers, tried to jump over a fence, ended up with a nasty gash on my leg. i'm not a good cop.\"]\n"
     ]
    }
   ],
   "source": [
    "src_text = [\n",
    "    \"\"\"this happened 5/6 years ago so my whole family every xmas day goes around to my aunties for celebrations. my cousin (of course) was there and he\n",
    "asked if i wanted to play cops and robbers. i accepted of course. now, next to the side of my aunts house is a little area with a small fence, a covered\n",
    "water tank and super duper sharp stones. my cousin (who was the cop) was gaining on me. i (tried) to jump over the fence, aaand i failed the jump\n",
    "and went crashing onto the gravel, my leg hitting the sharpest bit and, then the next thing i knew it had a nasty gash.\"\"\"\n",
    "]\n",
    "\n",
    "\n",
     "#batch = tokenizer.prepare_seq2seq_batch(src_text, truncation=True, padding='longest').to(torch_device)\n",
    "batch = tokenizer.prepare_seq2seq_batch(src_text, truncation=True, padding='longest', return_tensors='pt').to(torch_device)",
    "translated = model.generate(**batch)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "print(tgt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['went off-roading with friends and brought a friend’s dog along. the dog went in and out of vision, biting the tires, and i felt the dreaded ’double-thud’ under the tires and heard the dog yelp in pain.']\n"
     ]
    }
   ],
   "source": [
    "src_text = [\n",
    "    \"\"\"throwaway here for obvious reasons.. today my friends and i decided to go off-roading in nowhereland. we packed up all our stuff, made the roughly\n",
    "hour drive off to the mountains to make a fire, go fishing and just talk about life until we got too tired to stay any longer. we got everything packed\n",
    "up and brought along one of my friends’ dog because she’s awesome and loves the outdoors. the dog was flipping out in the suv on the way to the\n",
    "path because she knew was a kick-ass day she was about to have breaking out of her normally lame, domesticated dog life. my friends decided to\n",
    "drink during the off-roading adventure, which was fine because i volunteered to drive since i cannot drink alcohol (mouth is wired shut [long story\n",
    "but i can’t drink alcohol for a while]) so we were playing it safe. the dog couldn’t be any happier and was about to jump out of the truck (literally)\n",
    "when we got there so the dog’s owner let her get out and run along side of us while we drove the dirt road up to the destination for the fire. as i was\n",
    "driving, the dog went in and out of vision, mostly biting the tires as most dogs do, playing around. the owner kept asking us (the two guys up front)\n",
    "if we could see her. we said yes, and kept driving. as i was driving at no more than 5-10mph along the dirt road, i could hear the dog biting at the\n",
    "tires playfully, but we just laughed it off bc we thought she was having fun. the horrible, seconds-long event that ensued was me feeling the dreaded\n",
    "’double-thud’ under the tires and heard the dog yelp in pain. i instantly stopped the ... .\"\"\"\n",
    "]\n",
    "\n",
    "\n",
     "#batch = tokenizer.prepare_seq2seq_batch(src_text, truncation=True, padding='longest').to(torch_device)\n",
    "batch = tokenizer.prepare_seq2seq_batch(src_text, truncation=True, padding='longest', return_tensors='pt').to(torch_device)",
    "translated = model.generate(**batch)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "print(tgt_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
